{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkwNS-qvTeUj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "pip install lightning vizta tensorboard git+https://github.com/wfondrie/depthcharge.git@asms \n",
    "for FILE in \"train.hdf5 24635459\" \"valid.hdf5 24635442\" \"test.hdf5 24635438\"\n",
    "do\n",
    "    set -- $FILE\n",
    "    if [ ! -f $1 ]; then\n",
    "        wget -nc https://figshare.com/ndownloader/files/$2\n",
    "        mv $2 $1\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18129,
     "status": "ok",
     "timestamp": 1685310171518,
     "user": {
      "displayName": "Will Fondrie",
      "userId": "00004301715304315122"
     },
     "user_tz": 420
    },
    "id": "3X0ta8JFpslm",
    "outputId": "db1480e5-468e-4a1d-f11e-7c936b2fc8d1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import einops\n",
    "import h5py\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import vizta\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from depthcharge.data import PeptideDataset\n",
    "from depthcharge.encoders import FloatEncoder\n",
    "from depthcharge.feedforward import FeedForward\n",
    "from depthcharge.tokenizers import PeptideTokenizer\n",
    "from depthcharge.transformers import PeptideTransformerEncoder\n",
    "\n",
    "# Set our plotting theme:\n",
    "pal = vizta.mpl.set_theme(context=\"notebook\", style=\"wfondrie\")\n",
    "\n",
    "# Set random seeds\n",
    "pl.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "executionInfo": {
     "elapsed": 4957,
     "status": "ok",
     "timestamp": 1685310176468,
     "user": {
      "displayName": "Will Fondrie",
      "userId": "00004301715304315122"
     },
     "user_tz": 420
    },
    "id": "TFsgECNj7g54",
    "outputId": "61f0cac6-8a17-4299-d4c2-198cf8b4b630"
   },
   "outputs": [],
   "source": [
    "tokenizer = PeptideTokenizer.from_proforma(\n",
    "    sequences=\"ACDEFGHIKLMNPQRSTVWYM[Oxidation]\", \n",
    "    replace_isoleucine_with_leucine=False, \n",
    "    reverse=False,\n",
    ")\n",
    "\n",
    "pd.DataFrame(tokenizer.residues.items(), columns=[\"Token\", \"Mass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "joOG84U1piP9",
    "outputId": "e01452b0-0f29-4a1e-b520-1a4dddf0b638"
   },
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def vecs2seqs(vecs, alphabet):\n",
    "    \"\"\"Convert Prosit vectors to peptide sequenes\"\"\"\n",
    "    for idx, seq_idx in enumerate(vecs):\n",
    "        yield \"\".join([alphabet[i - 1] for i in seq_idx if i])\n",
    "\n",
    "@nb.njit\n",
    "def flip_and_shift_b_ions(ions, n_ions):\n",
    "    \"\"\"Flip the b_ions and shift them one down.\n",
    "\n",
    "    This let's them match the order of our Transformer model.\n",
    "    \"\"\"\n",
    "    for idx, n_ion in enumerate(n_ions): \n",
    "        ions[idx, 1:n_ion+1, 1, :] = ions[idx, n_ion-1::-1, 1, :]\n",
    "\n",
    "    return ions\n",
    "\n",
    "\n",
    "class PrositDataset(PeptideDataset):\n",
    "    \"\"\"A class for the Prosit HDF5 files.\"\"\"\n",
    "    def __init__(self, tokenizer, hdf5_file, max_examples=1_000_000):\n",
    "        \"\"\"Initialize the Prosit Dataset\"\"\"\n",
    "        alphabet = list(tokenizer.residues.keys())\n",
    "        with h5py.File(hdf5_file) as data:\n",
    "            n_rows = data[\"scan_number\"].shape[0]\n",
    "\n",
    "        if n_rows > max_examples:\n",
    "            # The peptides are lexigraphically sorted, so we'll take a \n",
    "            # diverse subset with creative indexing.\n",
    "            print(f\"  -> Found {n_rows} peptides. Subsetting to ~{max_examples}...\")\n",
    "            step = int(np.floor(n_rows / max_examples))\n",
    "        else:\n",
    "            step = 1\n",
    "\n",
    "        print(\"  -> Reading from HDF5 file....\")\n",
    "        with h5py.File(hdf5_file) as data:\n",
    "            charge = np.argmax(data[\"precursor_charge_onehot\"][::step], axis=1) + 1\n",
    "            charge = torch.tensor(charge).to(\"cuda\")\n",
    "            nce = torch.tensor(data[\"collision_energy_aligned_normed\"][::step]).to(\"cuda\")\n",
    "            seq = vecs2seqs(data[\"sequence_integer\"][::step], np.array(alphabet))\n",
    "            intensities = data[\"intensities_raw\"][::step]\n",
    "            n_rows = len(charge)\n",
    "\n",
    "        print(\"  -> Preprocessing intensities...\")\n",
    "        # Transform the intensities for our Transformer.\n",
    "        # Intensities are shape (L, I, Z) where:\n",
    "        # L = The peptide length - 1, ordered from lowest mass to highest.\n",
    "        # I = The ion series, (y, b)\n",
    "        # Z = The charge state (increasing)\n",
    "        intensities = intensities.reshape([n_rows, 29, 2, 3])\n",
    "        n_ions = (intensities[:, :, 0, 0] >= 0).sum(axis=1)\n",
    "        \n",
    "        # Need an extra space because we want to shift b ions.\n",
    "        intensities = np.pad(\n",
    "            intensities,\n",
    "            ((0, 0), (0, 1), (0, 0), (0, 0)), \n",
    "            \"constant\", \n",
    "            constant_values=-1,\n",
    "        )\n",
    "\n",
    "        intensities = flip_and_shift_b_ions(intensities, n_ions)\n",
    "        intensities[:, 0, 1, :] = -1\n",
    "        intensities = torch.tensor(intensities).to(\"cuda\")\n",
    "\n",
    "        print(\"  -> Tokenizing peptides...\")\n",
    "        super().__init__(tokenizer, seq, charge, nce, intensities)\n",
    "\n",
    "\n",
    "print(\"Loading the training dataset...\")\n",
    "train_dataset = PrositDataset(tokenizer, \"train.hdf5\", 200_000)\n",
    "print(\"Loading the validation dataset...\")\n",
    "validation_dataset = PrositDataset(tokenizer, \"valid.hdf5\", 100_000)\n",
    "print(\"Loading the test dataset...\")\n",
    "test_dataset = PrositDataset(tokenizer, \"test.hdf5\", 100_000)\n",
    "\n",
    "# The GPU memory on this instance is larger than the host, so\n",
    "# we put data on the gpu to run fast.\n",
    "for dset in (train_dataset, validation_dataset, test_dataset):\n",
    "    tensors = []\n",
    "    for data in dset.tensors:\n",
    "        tensors.append(data.to(\"cuda\"))\n",
    "\n",
    "    dset.tensors = tuple(tensors)\n",
    "\n",
    "train_loader = train_dataset.loader(\n",
    "    batch_size=128, shuffle=True,\n",
    ")\n",
    "validation_loader = validation_dataset.loader(\n",
    "    batch_size=1024, shuffle=False,\n",
    ")\n",
    "\n",
    "test_loader = test_dataset.loader(\n",
    "    batch_size=1024, shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FfpuXOUtL8xj"
   },
   "outputs": [],
   "source": [
    "def masked_spectral_angle(true, pred):\n",
    "    \"\"\"This is an PyTorch adaptation of the Prosit implementation here:\n",
    "    https://github.com/kusterlab/prosit/blob/dd16c47f8c3f4cfbd7ae84a1ca92a4d117e5e9ec/prosit/losses.py#L4-L16\n",
    "    \"\"\"\n",
    "    true = true.flatten(start_dim=1)\n",
    "    pred = pred.flatten(start_dim=1)\n",
    "    epsilon = torch.finfo(torch.float32).eps\n",
    "    pred_masked = ((true + 1) * pred) / (true + 1 + epsilon)\n",
    "    true_masked = ((true + 1) * true) / (true + 1 + epsilon)\n",
    "    pred_norm = F.normalize(true_masked, p=2, dim=-1)\n",
    "    true_norm = F.normalize(pred_masked, p=2, dim=-1)\n",
    "    product = torch.sum(pred_norm * true_norm, dim=1)\n",
    "    arccos = torch.acos(product)\n",
    "    return 2 * arccos / np.pi\n",
    "\n",
    "\n",
    "class FragmentPredictor(pl.LightningModule):\n",
    "    \"\"\"A Transformer model for CCS prediction\"\"\"\n",
    "    def __init__(self, tokenizer, d_model, n_layers):\n",
    "        \"\"\"Initialize the CCSPredictor\"\"\"\n",
    "        super().__init__()\n",
    "        self.peptide_encoder = PeptideTransformerEncoder(\n",
    "            n_tokens=tokenizer,\n",
    "            d_model=d_model,\n",
    "            n_layers=n_layers,\n",
    "            max_charge=10,\n",
    "        )\n",
    "        self.nce_encoder = FloatEncoder(d_model, max_wavelength=1)\n",
    "        self.fragment_head = FeedForward(d_model, 6, 3)\n",
    "\n",
    "    def step(self, batch, batch_idx):\n",
    "        \"\"\"A training/validation/inference step.\"\"\"\n",
    "        seqs, charges, nce, intensities = batch\n",
    "        embedded, mask = self.peptide_encoder(seqs, charges)\n",
    "        emb_nce = self.nce_encoder(nce[:, None])\n",
    "        pred = self.fragment_head(embedded + emb_nce) \n",
    "\n",
    "        # Reshape for the Prosit data:\n",
    "        pred = einops.rearrange(pred, \"B L (I Z) -> B I Z L\", I=2)\n",
    "        pred = F.pad(pred, (0, 30 - pred.shape[-1]), \"constant\", 0)\n",
    "        pred = einops.rearrange(pred, \"B I Z L -> B L I Z\")\n",
    "\n",
    "        # Calculate the loss\n",
    "        if intensities is not None:\n",
    "            intensities = intensities.type_as(pred)\n",
    "            loss = masked_spectral_angle(intensities, pred).mean()\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return pred, loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"A training step\"\"\"\n",
    "        _, loss = self.step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"A validation step\"\"\"\n",
    "        _, loss = self.step(batch, batch_idx)\n",
    "        self.log(\"validation_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        \"\"\"An inference step\"\"\"\n",
    "        pred, _ = self.step(batch, batch_idx)\n",
    "        return pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure the optimizer for training.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QED9S2nEWluw",
    "outputId": "01b0bdc8-c8a2-49de-d0b2-8b4092b6ddec"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYcxB_F9UKGY"
   },
   "outputs": [],
   "source": [
    "# Create a model:\n",
    "model = FragmentPredictor(tokenizer, d_model=64, n_layers=6)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"validation_loss\", patience=3)\n",
    "trainer = pl.Trainer(\n",
    "    #accelerator=\"cpu\", \n",
    "    callbacks=[early_stopping],\n",
    "    max_epochs=10, \n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    model=model, \n",
    "    train_dataloaders=train_loader, \n",
    "    val_dataloaders=validation_loader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyONLhOSgQJd2HTaCfj3nSx1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
